{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u93YJyjNB9WK"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this assignment you will practice calibrating a camera, computing homography between images and stitching panoramas. The goals of this assignment are as follows:\n",
        "\n",
        "\n",
        "\n",
        "*   Understand the intrinsic parameters of a prospective camera.\n",
        "*   Understand feature detection and feature matching process.\n",
        "*   Find the intrinsic and extrinsic parameters of a camera using chessboard patterns.\n",
        "*   Compute homography between two images.\n",
        "*   Use homography to stitch panoramas.\n",
        "\n",
        "Please fill in all the **TODO** blocks (including codes and texts). Most of the assignment can be done by calling functions in OpenCV. However, if you try to implement those functions by yourself, you will get extra points (up to 20 pts). Once you are ready to submit:\n",
        "\n",
        "* Export the notebook `CSCI677_assignment_2.ipynb` as a PDF `[Your USC ID]_CSCI677_assignment_2.pdf`\n",
        "* Submit your PDF file through [Blackboard](https://blackboard.usc.edu/)\n",
        "\n",
        "Please make sure that the notebook have been run before exporting PDF, and your code and all cell outputs are visible in your submitted PDF. Regrading request will not be accepted if your code/output is not visible in the original submission. Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSd79LFHy0tx"
      },
      "source": [
        "# Data Unzip\n",
        "We provided data for each of the section below. To acquire and unzip the data in Google Colab, first copy the file `data.zip` from [link](https://drive.google.com/file/d/1Dkd1fIvu0ckkhMgX1JaTnAb52mTiuMvM/view?usp=sharing) to your own Google Drive, and then run the following code. If `data.zip` is not in the root folder of your Google Drive, you need to change `zip_file_path`.\n",
        "\n",
        "If you are completing the assignment on your own PC (not using Google Colab), then simply download `data.zip` from the [link](https://drive.google.com/file/d/1Dkd1fIvu0ckkhMgX1JaTnAb52mTiuMvM/view?usp=sharing) and extract to a location you prefer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDcSNBAP1HcZ"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# import zipfile\n",
        "\n",
        "# # Path to the zip file on your Google Drive\n",
        "# zip_file_path = '/content/drive/My Drive/data.zip'\n",
        "\n",
        "# # Destination folder where you want to extract the zip file\n",
        "# destination_folder = '/content/data'\n",
        "\n",
        "# # Unzipping the zip file\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(destination_folder)\n",
        "\n",
        "# print(f'Contents of {zip_file_path} have been extracted to {destination_folder}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr_Wv6Hi3Y_K"
      },
      "source": [
        "# Calibration (35 pts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp9dU9BxtSsd"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "To find out the intrinsic parameters of a camera, we need to prepare sample images of a chessboard pattern. This is done by taking photos of printed chessboard patterns or of chessboard patterns displayed on a flat screen. To achieve better accuracy, we need at least 10 of them from different angles. We provided sample images in the folder `calibration`, but we encourage you to try with your own camera or smartphone. You might find the following website useful for generating chessboard patterns of your preferred size:\n",
        "https://markhedleyjones.com/projects/calibration-checkerboard-collection\n",
        "\n",
        "Please make sure that every photo you take covers the entire chessboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SbMjLtFVo4F"
      },
      "source": [
        "## Pattern Recognition (10 pts)\n",
        "\n",
        "To locate the chessboard pattern in the photos, you can use cv.findChessboardCorners(). You can refer to the code in\n",
        "https://docs.opencv.org/4.8.0/dc/dbb/tutorial_py_calibration.html\n",
        "\n",
        "Remember to change the sizes based on your own chessboard size. After you locate the corners, display one image with the chessboard pattern drawn on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2SblUqg6X667"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import glob\n",
        "import os\n",
        "\n",
        "images = glob.glob('data/calibration/*.jpg')\n",
        "\n",
        "\n",
        "# TODO\n",
        "# generate the groundtruth \n",
        "groundtruth = np.zeros((48,3), np.float32)\n",
        "for i in range(48):\n",
        "    groundtruth[i, 0] = i % 8\n",
        "    groundtruth[i, 1] = i // 8\n",
        "# print(groundtruth)\n",
        "\n",
        "# termination\n",
        "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\n",
        "# Arrays to store object points and image points from all the images.\n",
        "objpoints = [] # 3d point in real world space\n",
        "imgpoints = [] # 2d points in image plane.\n",
        "for fname in images:\n",
        "    img = cv.imread(fname)\n",
        "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "    # Find the chess board corners\n",
        "    ret, corners = cv.findChessboardCorners(gray, (7,6), None)\n",
        "    # If found, add object points, image points (after refining them)\n",
        "    if ret == True:\n",
        "        objpoints.append(groundtruth)\n",
        "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
        "        imgpoints.append(corners2)\n",
        "# Draw and display the corners\n",
        "cv.drawChessboardCorners(img, (7,6), corners2, ret)\n",
        "cv.imshow('img', img)\n",
        "cv.waitKey(500)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwdMZskzXL_T"
      },
      "source": [
        "## Calibration (10 pts)\n",
        "\n",
        "Now you are ready to calibrate the camera. You can use the function cv.calibrateCamera(), but you will get extra points (+5 pts) if you implement it by yourself.\n",
        "\n",
        "After calibration, print the intrinsic parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnUrXKXQX3im"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqTgMdOGZU-n"
      },
      "source": [
        "## Pose Estimation (10 pts)\n",
        "\n",
        "After you got the camera parameters, you can utilize the information to calculate the pose of a chessboard in a pattern image and display cool things. Follow the tutorial in\n",
        "https://docs.opencv.org/4.8.0/d7/d53/tutorial_py_pose.html\n",
        "\n",
        "Choose one of the following three to display:\n",
        "\n",
        "* Render three axes on the chessboard image\n",
        "* Render a cube on the chessboard image\n",
        "* Render something you find cool (more complicated than three axes or a cube)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9q0t2na3a8JZ"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4XvdbWSWw9x"
      },
      "source": [
        "## Observation (5 pts)\n",
        "Write down your observations regarding the results you obtained throughout the `Calibration` section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxoBM-RcWw9x"
      },
      "source": [
        "## **TODO: write down your observations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNrlXTeKbkUf"
      },
      "source": [
        "# Homography (35 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcVMJdIfcDoh"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "To compute homography, you need to prepare one photo of an object (e.g. a book) and one photo of the same object in a different scene. We provided an example in the folder `homography`, but we encourage you to take photos with your own camera or smartphone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqVYz91Cdsf6"
      },
      "source": [
        "## Feature Detection (10 pts)\n",
        "\n",
        "After you have the two photos, load them using cv.imread(). Convert them to grayscale images. Create a SIFT feature detector. Detect the keypoints on both images and display them with size and orientation. You can follow the tutorial in https://docs.opencv.org/4.8.0/da/df5/tutorial_py_sift_intro.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCXxIvuZgClz"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-rCkw4TgIOE"
      },
      "source": [
        "## Feature Matching (10 pts)\n",
        "\n",
        "Create a brute force matcher. Find matches among the descriptors you just detected on the two images. Filter them with the ratio test. Display the resulting matches between the two images. You can follow the tutorial in https://docs.opencv.org/4.5.2/dc/dc3/tutorial_py_matcher.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CKOVvDhhQGC"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOCKkk1zjCAd"
      },
      "source": [
        "## Compute Homography (10 pts)\n",
        "\n",
        "Compute the homography using RANSAC. Print out the homography matrix. Transform the four corners of the source image using the homography and display the transformed rectangle on the destination image. You can follow the tutorial in https://docs.opencv.org/4.5.2/d1/de0/tutorial_py_feature_homography.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Bz5XpSFwFi9"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpLHzi5MWGaj"
      },
      "source": [
        "## Observation (5 pts)\n",
        "Write down your observations regarding the results you obtained throughout the `Homography` section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaWOQju9WhXA"
      },
      "source": [
        "## **TODO: write down your observations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_W6pEH7wi0o"
      },
      "source": [
        "# Panorama (30 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge2sOv3ywzt8"
      },
      "source": [
        "## Data Preparation\n",
        "To stitch photos into a panorama, you need to prepare two or more photos of the same scene. There should be enough intersection between two consecutive photos. Again, we provided an example in the folder `panorama`, but we encourage you to take photos with your own camera or smartphone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOLpNVEXxhJq"
      },
      "source": [
        "## Compute Homography (10 pts)\n",
        "Here we are computing homography again, but once every two consecutive images. To do this, you need to first import the images. Then you pick a feature detector (not necessarily SIFT) and detect features. Then you pick a feature matcher (not necessarily brute-force) and find matches between every two consecutive images. Then you compute homography and store them. Below we write a skeleton for you, but you needn't follow it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHDMzO05yuBE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "\n",
        "# read images\n",
        "input_path = 'data/panorama/'\n",
        "filenames = [input_path + filename for filename in os.listdir(input_path)]\n",
        "images = [cv.imread(filename) for filename in filenames]\n",
        "count = len(images)\n",
        "\n",
        "homography_matrices = []\n",
        "for i in range(count-1):\n",
        "    # convert to grayscale images\n",
        "    gray1 = cv.cvtColor(images[i], cv.COLOR_BGR2GRAY)\n",
        "    gray2 = cv.cvtColor(images[i+1], cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk72Lv9Cyw6U"
      },
      "source": [
        "## Stitch Panorama (15 pts)\n",
        "Now we can stitch those images to compose a panorama. You need to select an image as an anchor and transform other images onto this anchor image. The transformation between any image and this anchor image is the composition of a series of homography. You should compute the transformations and map all other images onto the anchor image. You can explore other ways to define an anchor. Then you need to blend these image. A possible way is to just take the maximum of the pixel values, but you are encouraged to explore other blending methods (extra points +2~5 pts). After you obtained your panorama, display it along with some intermediate results including feature matches and transformed images. We attached an example in the folder `panorama_output`. Below we provide the code to compute the size of a rectangle that covers all transformed images, but you needn't follow it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xP8B061aeOr"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "# TODO: some processing of the homography matrices\n",
        "\n",
        "min_x = min_y = max_x = max_y = 0.0\n",
        "for i in range(count):\n",
        "    # Get the height and width of the original images\n",
        "    h, w, p = images[i].shape\n",
        "    # Create a list of points to represent the corners of the images\n",
        "    corners = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype=np.float32)\n",
        "    # Calculate the transformed corners\n",
        "    transformed_corners = cv.perspectiveTransform(corners.reshape(-1, 1, 2), homography_matrices[i])\n",
        "    # Find the minimum and maximum coordinates to determine the output size\n",
        "    min_x = min(transformed_corners[:, 0, 0].min(), min_x)\n",
        "    min_y = min(transformed_corners[:, 0, 1].min(), min_y)\n",
        "    max_x = max(transformed_corners[:, 0, 0].max(), max_x)\n",
        "    max_y = max(transformed_corners[:, 0, 1].max(), max_y)\n",
        "\n",
        "# Calculate the width and height of the stitched image\n",
        "output_width = int(max_x - min_x)\n",
        "output_height = int(max_y - min_y)\n",
        "\n",
        "\n",
        "# TODO: blend the transformed images\n",
        "\n",
        "# TODO: display the panorama along with some intermediate results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWelnlpRWsnT"
      },
      "source": [
        "## Observation (5 pts)\n",
        "Write down your observations regarding the results you obtained throughout the `Panorama` section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RL5J3s7Kyu4_"
      },
      "source": [
        "## **TODO: write down your observations**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
